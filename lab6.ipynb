{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for column in ['Book-Title', 'Book-Author', 'Publisher']:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos en entrenamiento y prueba\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de datos numéricos\n",
    "scaler = StandardScaler()\n",
    "train[['Year-Of-Publication']] = scaler.fit_transform(train[['Year-Of-Publication']])\n",
    "test[['Year-Of-Publication']] = scaler.transform(test[['Year-Of-Publication']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25779/25779 [==============================] - 18s 689us/step - loss: 22138.7910\n",
      "Epoch 2/5\n",
      "25779/25779 [==============================] - 18s 710us/step - loss: 1453.7455\n",
      "Epoch 3/5\n",
      "25779/25779 [==============================] - 17s 666us/step - loss: 360.1299\n",
      "Epoch 4/5\n",
      "25779/25779 [==============================] - 18s 688us/step - loss: 97.4373\n",
      "Epoch 5/5\n",
      "25779/25779 [==============================] - 17s 675us/step - loss: 30.5576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x196cc5db9d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train[['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']], train['Book-Rating'], epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8401/8401 [==============================] - 5s 541us/step\n"
     ]
    }
   ],
   "source": [
    "user_id = 276725\n",
    "\n",
    "# Filtrar los libros que el usuario no ha valorado\n",
    "unrated_books = data[~data['User-ID'].isin([user_id])][['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']].drop_duplicates()\n",
    "\n",
    "# Realizar predicciones para los libros no valorados por el usuario\n",
    "predictions = model.predict(unrated_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Book-Title  Book-Author  Publisher  Year-Of-Publication  \\\n",
      "899768        4842          212      16139                 1999   \n",
      "35404        10512        98618      14181                    0   \n",
      "680873       10421        99877      13677                    0   \n",
      "786552       38411       100931      15331                    0   \n",
      "821169       10836        87263      15864                    0   \n",
      "576261       21876        96148      15647                    0   \n",
      "784262       15857        92722      14950                    0   \n",
      "428397        3731          507      13190                 2000   \n",
      "528329       33883        99306      15189                    0   \n",
      "424826       29278       101451      14693                    0   \n",
      "\n",
      "        Predicted_Rating  \n",
      "899768          6.931890  \n",
      "35404           5.422204  \n",
      "680873          5.413890  \n",
      "786552          5.345872  \n",
      "821169          5.294159  \n",
      "576261          5.268323  \n",
      "784262          5.252815  \n",
      "428397          5.249682  \n",
      "528329          5.193383  \n",
      "424826          5.176871  \n"
     ]
    }
   ],
   "source": [
    "# Agregar las predicciones al DataFrame de los libros no valorados\n",
    "unrated_books['Predicted_Rating'] = predictions\n",
    "\n",
    "# Mostrar los 10 libros con las calificaciones predichas más altas\n",
    "top_recommendations = unrated_books.sort_values(by='Predicted_Rating', ascending=False).head(10)\n",
    "print(top_recommendations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
